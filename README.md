# MCP Knowledge Base Server

[![Tests](https://github.com/yourusername/mcp-knowledge-base/workflows/Tests/badge.svg)](https://github.com/yourusername/mcp-knowledge-base/actions)
[![PyPI version](https://badge.fury.io/py/mcp-knowledge-base.svg)](https://badge.fury.io/py/mcp-knowledge-base)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A Model Context Protocol (MCP) server that provides document ingestion, indexing, and semantic search capabilities using LanceDB as the vector database.

**Give your local LLM the ability to search and understand your codebase** - Works with Claude Desktop, Kiro IDE, Continue.dev, and other MCP clients.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Your LLM Client                              â”‚
â”‚              (Claude Desktop, Kiro IDE, Continue.dev)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚ MCP Protocol
                                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Knowledge Base Server                         â”‚
â”‚                                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  add_document   â”‚  â”‚ search_documents â”‚  â”‚ list_documents   â”‚  â”‚
â”‚  â”‚                 â”‚  â”‚                  â”‚  â”‚                  â”‚  â”‚
â”‚  â”‚  Ingests files  â”‚  â”‚  Semantic search â”‚  â”‚  Browse indexed  â”‚  â”‚
â”‚  â”‚  (.py, .txt)    â”‚  â”‚  with vectors    â”‚  â”‚  documents       â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                    â”‚                      â”‚             â”‚
â”‚           â–¼                    â–¼                      â–¼             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Document Processing Pipeline                     â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚  1. Content Extraction  â†’  2. Chunking  â†’  3. Embedding      â”‚  â”‚
â”‚  â”‚     â€¢ File reading          â€¢ Smart split    â€¢ Sentence       â”‚  â”‚
â”‚  â”‚     â€¢ Encoding detect       â€¢ Overlap        Transformers     â”‚  â”‚
â”‚  â”‚     â€¢ Hash generation       â€¢ Metadata       â€¢ Local model    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                â–¼                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                    LanceDB Vector Store                       â”‚  â”‚
â”‚  â”‚                                                                â”‚  â”‚
â”‚  â”‚  ğŸ“„ Documents Table          ğŸ“¦ Chunks Table                  â”‚  â”‚
â”‚  â”‚  â€¢ Metadata                  â€¢ Text content                   â”‚  â”‚
â”‚  â”‚  â€¢ File paths                â€¢ 384-dim vectors                â”‚  â”‚
â”‚  â”‚  â€¢ Timestamps                â€¢ Document refs                  â”‚  â”‚
â”‚  â”‚  â€¢ Chunk counts              â€¢ Fast ANN search                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                    ğŸ’¾ Local Storage (100% Offline)
                    â€¢ knowledge_base.db
                    â€¢ Embedding model cache
                    â€¢ No external API calls
```

## Features

- **ğŸ” Semantic Search** - Find code by meaning, not just keywords
- **ï¿½  GitHub Integration** - Add entire repositories with one command
- **ï¿½ FSmart Chunking** - Intelligent text splitting with overlap for better context
- **ï¿½ F0ast Vector Search** - LanceDB's approximate nearest neighbor search
- **ğŸ”’ 100% Local** - All processing happens on your machine, no data leaves
- **ğŸ¯ MCP Native** - Built specifically for the Model Context Protocol
- **âš¡ Easy Setup** - One command with `uvx`, no configuration needed
- **ï¿½ Pyth-on & Text** - Supports .py and .txt files (more formats coming)
- **ğŸ”„ Real-time Updates** - Add/remove documents on the fly

## Installation

### For Published Package (Coming Soon)

Once published to PyPI, no manual installation needed! Just configure your LLM client with `uvx`.

### For Local Development (Current)

Since the package isn't published yet, install it locally:

```bash
# Navigate to the project directory
cd /path/to/mcp-knowledge-base

# Install dependencies and the package
pip install -r requirements.txt
pip install -e .

# Verify installation
mcp-knowledge-base --version
```

Then configure your LLM client to use the installed command (see [Setup](#setup-with-your-llm) below).

## What You Can Add

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Supported Input Types                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                       â”‚
â”‚  ğŸ“ Local Files & Directories                                        â”‚
â”‚  â”œâ”€ Single file:      /path/to/script.py                            â”‚
â”‚  â”œâ”€ Directory:        /path/to/project/src/                         â”‚
â”‚  â””â”€ Recursive:        Automatically processes subdirectories         â”‚
â”‚                                                                       â”‚
â”‚  ğŸ™ GitHub Repositories (Public)                                     â”‚
â”‚  â”œâ”€ Entire repo:      https://github.com/user/repo                  â”‚
â”‚  â”œâ”€ Specific branch:  https://github.com/user/repo/tree/develop     â”‚
â”‚  â”œâ”€ Subdirectory:     https://github.com/user/repo/tree/main/src    â”‚
â”‚  â””â”€ Single file:      https://github.com/user/repo/blob/main/file.pyâ”‚
â”‚                                                                       â”‚
â”‚  ğŸ“„ Supported File Types                                             â”‚
â”‚  â”œâ”€ Python:           .py                                            â”‚
â”‚  â”œâ”€ Text:             .txt                                           â”‚
â”‚  â””â”€ Markdown:         .md (coming soon)                              â”‚
â”‚                                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ğŸ’¡ Try These Popular Repositories

**Web Frameworks:**
```
https://github.com/django/django          # Django web framework
https://github.com/pallets/flask          # Flask microframework  
https://github.com/fastapi/fastapi        # FastAPI modern framework
```

**Data Science:**
```
https://github.com/pandas-dev/pandas      # Pandas data analysis
https://github.com/scikit-learn/scikit-learn  # Machine learning
https://github.com/pytorch/pytorch        # PyTorch deep learning
```

**Utilities:**
```
https://github.com/psf/requests           # HTTP library
https://github.com/python/cpython         # Python itself!
https://github.com/pallets/click          # CLI framework
```

**Learn Specific Features:**
```
https://github.com/django/django/tree/main/django/contrib/auth  # Django auth
https://github.com/fastapi/fastapi/tree/master/fastapi          # FastAPI core
https://github.com/requests/requests/tree/main/requests         # Requests lib
```

## Available Tools

Once connected to your LLM, you get four powerful tools:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ“¥ add_document(file_path_or_url)                               â”‚
â”‚    Add documents to the knowledge base                          â”‚
â”‚    â†’ Local files: "/path/to/file.py"                            â”‚
â”‚    â†’ GitHub repos: "https://github.com/user/repo"               â”‚
â”‚    â†’ GitHub files: "https://github.com/user/repo/blob/main/..." â”‚
â”‚    â†’ Extracts content, creates embeddings, stores in LanceDB    â”‚
â”‚                                                                  â”‚
â”‚ ğŸ” search_documents(query, limit=10)                            â”‚
â”‚    Semantic search across all documents                         â”‚
â”‚    â†’ Finds relevant code/text by meaning, not just keywords     â”‚
â”‚                                                                  â”‚
â”‚ ğŸ“‹ list_documents(limit=100, offset=0)                          â”‚
â”‚    List all indexed documents with pagination                   â”‚
â”‚    â†’ Browse what's in your knowledge base                       â”‚
â”‚                                                                  â”‚
â”‚ ğŸ—‘ï¸  clear_knowledge_base()                                      â”‚
â”‚    Remove all documents and start fresh                         â”‚
â”‚    â†’ Clean slate when needed                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Example Conversations

**Adding a GitHub Repository:**
```
You: Add the FastAPI repository to my knowledge base

LLM: I'll add the FastAPI repository for you.
     [Calls add_document("https://github.com/tiangolo/fastapi")]
     
     Cloning repository...
     Processing 247 Python files...
     âœ“ Added 247 files from repository with 1,543 chunks
     
     You can now ask questions about FastAPI's implementation!

You: How does FastAPI handle dependency injection?

LLM: [Searches the FastAPI codebase...]
     Based on the FastAPI source code, dependency injection works through...
```

**Adding Local Files:**
```
You: Add all Python files in my src/ directory to the knowledge base

LLM: I'll add those files for you.
     [Calls add_document for each .py file]
     âœ“ Added 15 Python files to the knowledge base

You: How do we handle authentication in this codebase?

LLM: Let me search for authentication-related code.
     [Calls search_documents with query "authentication handling"]
     
     Based on the code, you use JWT tokens with OAuth2. Here's what I found:
     - src/auth/jwt.py: Token generation and validation
     - src/auth/oauth.py: OAuth2 flow implementation
     - src/middleware/auth.py: Authentication middleware
     
     The main authentication flow is...
```

## Quick Start Examples

### Example 1: Add Your Project
```
You: Add all Python files from /Users/me/my-project/src to the knowledge base

LLM: [Processes all .py files in the directory]
     âœ“ Added 23 Python files with 156 chunks
```

### Example 2: Learn from Open Source
```
You: Add the FastAPI repository so I can learn how it works

LLM: [Calls add_document("https://github.com/tiangolo/fastapi")]
     Cloning repository...
     âœ“ Added 247 files from repository with 1,543 chunks
     
You: How does FastAPI handle dependency injection?

LLM: [Searches and explains based on actual FastAPI source code]
```

### Example 3: Research a Specific Feature
```
You: Add just the authentication module from Django

LLM: [Calls add_document("https://github.com/django/django/tree/main/django/contrib/auth")]
     âœ“ Added 45 files from django/contrib/auth with 312 chunks

You: Show me how Django implements password hashing

LLM: [Provides detailed explanation with code references]
```

## Example Queries

Once you've added documents, here are powerful queries you can ask:

### ğŸ” Understanding Code
```
"How does this codebase handle database connections?"
"Explain the authentication flow in this project"
"What design patterns are used in this repository?"
"How is error handling implemented?"
"Show me how the API endpoints are structured"
```

### ğŸ› Debugging & Problem Solving
```
"Find examples of how to handle file uploads"
"Where is the rate limiting logic implemented?"
"Show me similar error handling patterns"
"How do other files handle this exception?"
"Find all places where we validate user input"
```

### ğŸ“š Learning & Research
```
"How does FastAPI implement dependency injection?"
"Compare how Django and Flask handle routing"
"What's the difference between these two implementations?"
"Show me examples of async/await usage in this codebase"
"How does this library handle backwards compatibility?"
```

### â™»ï¸ Refactoring & Code Review
```
"Find all files that use the old authentication method"
"Where else do we use this deprecated function?"
"Show me similar code that might have the same bug"
"Find duplicate logic that could be refactored"
"What files would be affected if I change this interface?"
```

### ğŸ¯ Specific Implementation Questions
```
"How do I use the caching system in this project?"
"Show me examples of writing tests for API endpoints"
"How is configuration managed in this codebase?"
"Find examples of custom middleware implementation"
"How do I add a new database model?"
```

### ğŸŒŸ Open Source Exploration
```
"How does React implement hooks internally?"
"Show me how Django's ORM builds SQL queries"
"How does FastAPI achieve such high performance?"
"Explain how pytest's fixture system works"
"How does requests handle HTTP retries?"
```

### ğŸ’¡ Tips for Better Queries

**âœ… Good Queries:**
- Be specific: "How does FastAPI validate request bodies?"
- Ask about concepts: "Explain the middleware pattern in this code"
- Request examples: "Show me examples of async database queries"
- Compare: "How is this different from the old implementation?"

**âŒ Avoid:**
- Too vague: "Tell me about the code"
- Too broad: "Explain everything"
- Outside scope: Questions about code not in the knowledge base

## Setup with Your LLM

### Claude Desktop

1. **Edit your Claude config** (`~/Library/Application Support/Claude/claude_desktop_config.json` on macOS):

   **For local development (not yet published):**
   ```json
   {
     "mcpServers": {
       "knowledge-base": {
         "command": "mcp-knowledge-base"
       }
     }
   }
   ```

   **Once published to PyPI:**
   ```json
   {
     "mcpServers": {
       "knowledge-base": {
         "command": "uvx",
         "args": ["mcp-knowledge-base"]
       }
     }
   }
   ```

2. **Restart Claude Desktop**

3. **Start using it:**
   - "Add the file ./src/main.py to the knowledge base"
   - "Search for authentication implementation"
   - "What documents are in the knowledge base?"

### Kiro IDE

1. **Edit `.kiro/settings/mcp.json`** in your workspace:

   **For local development (not yet published):**
   ```json
   {
     "mcpServers": {
       "knowledge-base": {
         "command": "mcp-knowledge-base",
         "disabled": false,
         "autoApprove": ["list_documents", "search_documents"]
       }
     }
   }
   ```

   **Or use Python module directly:**
   ```json
   {
     "mcpServers": {
       "knowledge-base": {
         "command": "python",
         "args": ["-m", "mcp_knowledge_base.main"],
         "disabled": false,
         "autoApprove": ["list_documents", "search_documents"]
       }
     }
   }
   ```

   **Once published to PyPI:**
   ```json
   {
     "mcpServers": {
       "knowledge-base": {
         "command": "uvx",
         "args": ["mcp-knowledge-base"],
         "disabled": false,
         "autoApprove": ["list_documents", "search_documents"]
       }
     }
   }
   ```

2. **Reload MCP servers** (Command Palette â†’ "MCP: Reload Servers")

3. **Start using it** - Ask Kiro to search your documents!

### Continue.dev / Cursor / Other Clients

See [USAGE_WITH_LLM.md](docs/USAGE_WITH_LLM.md) for setup instructions.

## How It Works

### The Magic Behind the Scenes

```
1. ğŸ“„ Document Ingestion
   â”œâ”€ Read file content with encoding detection
   â”œâ”€ Generate content hash for deduplication
   â”œâ”€ Extract metadata (size, timestamps, type)
   â””â”€ Split into overlapping chunks (~1000 chars)

2. ğŸ§® Vector Embedding
   â”œâ”€ Load sentence-transformers model (all-MiniLM-L6-v2)
   â”œâ”€ Convert each chunk to 384-dimensional vector
   â”œâ”€ Batch processing for efficiency
   â””â”€ Store vectors in LanceDB

3. ğŸ” Semantic Search
   â”œâ”€ Convert search query to vector
   â”œâ”€ Find similar vectors using ANN (Approximate Nearest Neighbor)
   â”œâ”€ Rank results by cosine similarity
   â””â”€ Return relevant chunks with metadata

4. ğŸ’¾ Storage
   â”œâ”€ LanceDB: Fast columnar vector database
   â”œâ”€ Two tables: documents + chunks
   â”œâ”€ Efficient updates and deletes
   â””â”€ All data stays local
```

### First Run

On first use, `uvx` automatically:
- Downloads and installs the package
- Installs all dependencies  
- Downloads the embedding model (~100MB, one-time)
- Starts the server

The server then:
- Creates `knowledge_base.db` in your current directory
- Stores logs in `./logs`
- Supports `.py` and `.txt` files by default

**Zero configuration needed!**

## Why Use This?

### Traditional Keyword Search
```
You: "Find authentication code"
Result: Files containing the word "authentication"
Problem: Misses related concepts like "login", "auth", "credentials"
```

### Semantic Search with This MCP
```
You: "Find authentication code"  
Result: All auth-related code including:
  âœ“ Files about "login" and "sign in"
  âœ“ Code handling "credentials" and "tokens"
  âœ“ "Authorization" and "access control"
  âœ“ Related security implementations

Why: Understands meaning, not just words
```

### Real-World Use Cases

- **ğŸ” Code Discovery** - "How do we handle database connections?"
- **ğŸ“š Onboarding** - New team members understand the codebase faster
- **ğŸ› Debugging** - "Find similar error handling patterns"
- **â™»ï¸ Refactoring** - "Where do we use this deprecated pattern?"
- **ğŸ“– Documentation** - "Explain how the auth system works"
- **ğŸ¯ Code Review** - "Find related code that might be affected"
- **ğŸŒŸ Learn from OSS** - "Add the React repository and explain how hooks work"
- **ğŸ“¦ Library Research** - "Add this library and show me how to use feature X"

## Troubleshooting

**Server not starting?**
```bash
# Check installation
mcp-knowledge-base --version

# View logs
tail -f logs/mcp_knowledge_base.log
```

**First run is slow?**
The embedding model (~100MB) downloads on first use. This only happens once.

**Need help?** See the [documentation](#documentation) below.

## Technical Details

### Stack

- **MCP Framework**: FastMCP - Modern Python MCP implementation
- **Vector Database**: LanceDB - Fast, embedded vector database
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2 (384 dimensions)
- **Search**: Approximate Nearest Neighbor (ANN) with cosine similarity
- **Storage**: Columnar format with Apache Arrow

### Performance

- **Embedding Speed**: ~1000 tokens/second on CPU
- **Search Latency**: <100ms for most queries
- **Storage**: ~1KB per chunk (text + vector + metadata)
- **Memory**: ~500MB (model) + database size

### Supported File Types

Currently:
- `.py` - Python source code
- `.txt` - Plain text files

Coming soon:
- `.md` - Markdown
- `.js`, `.ts` - JavaScript/TypeScript
- `.java`, `.cpp` - Other languages

## Documentation

- **[LOCAL_DEVELOPMENT.md](LOCAL_DEVELOPMENT.md)** - ğŸ”§ Setup for local development (current - not yet published)
- **[INSTALL.md](INSTALL.md)** - Detailed setup guide for all LLM clients
- **[USAGE_WITH_LLM.md](docs/USAGE_WITH_LLM.md)** - Usage examples and tips

### Advanced

- **[DEPLOYMENT.md](docs/DEPLOYMENT.md)** - Manual installation, custom configuration, production deployment
- **[QUICKSTART.md](docs/QUICKSTART.md)** - Configuration options and advanced features

## Contributing

Contributions are welcome! This is an open-source project.

- Report bugs and request features via [GitHub Issues](https://github.com/yourusername/mcp-knowledge-base/issues)
- Submit pull requests for improvements
- Star the repo if you find it useful! â­

## License

MIT License